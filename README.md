# OSTicket Data Pipeline â€“ Databricks


Este projeto implementa um pipeline de dados, utilizando o Databricks Free Edition,
seguindo a arquitetura Bronze, Silver e Gold.

## ğŸ¯ Objetivo

Implementar um pipeline de engenharia de dados utilizando dados dos
chamados do TechOps, garantindo o processamento e mÃ©tricas prontas para consumo analÃ­tico.

## ğŸ” Sobre o OSTicket

OSTicket Ã© uma ferramenta de Service Desk e gerenciamento de chamados de cÃ³digo aberto.

Neste projeto, o OSTicket foi utilizado como fonte de dados dos tickets de suporte (TechOps), permitindo a construÃ§Ã£o de mÃ©tricas,
acompanhamento de SLA e anÃ¡lises histÃ³ricas de desempenho.

_Os dados usado do OSTicket neste projeto sÃ£o: ost_thread_entry.csv, ost_ticket.csv, ost_staff.csv, ost_ticket_cdata.csv, ost_ticket_status.csv_

## ğŸ—ï¸ Arquitetura de Dados
O pipeline segue o padrÃ£o:

Raw â†’ Bronze â†’ Silver â†’ Gold

- **Raw**: Armazenamento dos dados brutos (rastreamento e reprocessamento)
- **Bronze**: ingestÃ£o dos dados brutos
- **Silver**: tratamento, limpeza e transformaÃ§Ã£o
- **Gold**: agregaÃ§Ãµes e mÃ©tricas para consumo analÃ­tico

A execuÃ§Ã£o Ã© controlada por um notebook orquestrador, que garante a ordem correta entre as camadas.


## ğŸ§° Tecnologias Utilizadas
- Databricks Free Edition
- Apache Spark (PySpark / Spark SQL)
- Delta Lake
- GitHub (versionamento)

## ğŸ“ Estrutura do Projeto

```
|â”€â”€ pipelines/
    â”œâ”€â”€ bronze/
    â”œâ”€â”€ silver/
    â”œâ”€â”€ gold/
```

## â–¶ï¸ Como Executar o Pipeline

### ExecuÃ§Ã£o no Databricks

Este projeto Ã© desenvolvido e testado utilizando notebooks do Databricks,
permitindo iteraÃ§Ã£o rÃ¡pida, validaÃ§Ã£o visual dos dados e depuraÃ§Ã£o durante o desenvolvimento.

Para fins de versionamento e melhor legibilidade no GitHub,
os notebooks sÃ£o convertidos para arquivos `.py` (Source File),
que representam o snapshot do cÃ³digo em seu estado estÃ¡vel.

A execuÃ§Ã£o do pipeline ocorre exclusivamente via notebooks no Databricks.

### Passo a passo

1. Acesse o **Databricks Free Edition**
2. Abra o notebook `setup` e execute utilizando a opÃ§Ã£o **Run All** para criar o catalogo e os volumes
3. Certifique-se de que os dados brutos estejam disponÃ­veis no volume **Raw**
4. Abra o notebook `orquestrador`
5. Execute o notebook utilizando a opÃ§Ã£o **Run All**

O pipeline serÃ¡ executado automaticamente na seguinte ordem:

**Bronze â†’ Silver â†’ Gold**
## ğŸ“Š Camada Gold e MÃ©tricas AnalÃ­ticas
ğŸ” **Confidencialidade dos dados**

Por se tratar de um projeto baseado em dados reais de operaÃ§Ãµes internas de TechOps, todos os valores numÃ©ricos sensÃ­veis foram propositalmente ocultados ou anonimizados nos dashboards apresentados neste repositÃ³rio.

A estrutura, mÃ©tricas, indicadores, visualizaÃ§Ãµes e regras de negÃ³cio permanecem fiÃ©is ao cenÃ¡rio real, sendo o objetivo demonstrar modelagem de indicadores, design de dashboards e anÃ¡lise operacional, e nÃ£o a exposiÃ§Ã£o de dados confidenciais.****

As mÃ©tricas da camada Gold foram definidas com foco em anÃ¡lise operacional e acompanhamento de SLA.

â¡ï¸ [Clique aqui para ver o detalhamento das mÃ©tricas e dashboards no Power BI](docs/metricas_e_dashboard.md)



## ğŸ‘¤ Autor
Matheus Inhaia

